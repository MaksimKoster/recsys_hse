{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-25T16:49:37.221082Z","iopub.status.busy":"2024-10-25T16:49:37.220273Z","iopub.status.idle":"2024-10-25T16:49:37.229224Z","shell.execute_reply":"2024-10-25T16:49:37.228362Z","shell.execute_reply.started":"2024-10-25T16:49:37.221037Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/recsys-hse/user_features.csv\n","/kaggle/input/recsys-hse/item_features.csv\n","/kaggle/input/recsys-hse/SASRec.yaml\n","/kaggle/input/recsys-hse/submission_sample.csv\n","/kaggle/input/recsys-hse/BERT4Rec.yaml\n","/kaggle/input/recsys-hse/events.csv\n","/kaggle/input/lkllklklk/submission_best.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pip install -q hydra-core --upgrade pytorch_lightning recommenders"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:49:41.851647Z","iopub.status.busy":"2024-10-25T16:49:41.851276Z","iopub.status.idle":"2024-10-25T16:49:41.856091Z","shell.execute_reply":"2024-10-25T16:49:41.855235Z","shell.execute_reply.started":"2024-10-25T16:49:41.851614Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n","sys.path.append('../')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:49:54.968131Z","iopub.status.busy":"2024-10-25T16:49:54.967761Z","iopub.status.idle":"2024-10-25T16:50:00.316996Z","shell.execute_reply":"2024-10-25T16:50:00.316163Z","shell.execute_reply.started":"2024-10-25T16:49:54.968094Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Torch datasets and collate function.\n","\"\"\"\n","\n","import numpy as np\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset\n","\n","\n","class LMDataset(Dataset):\n","\n","    def __init__(self, df, max_length=128, num_negatives=None, full_negative_sampling=True,\n","                 user_col='user_id', item_col='item_id', time_col='time_idx'):\n","\n","        self.max_length = max_length\n","        self.num_negatives = num_negatives\n","        self.full_negative_sampling = full_negative_sampling\n","        self.user_col = user_col\n","        self.item_col = item_col\n","        self.time_col = time_col\n","\n","        self.data = df.sort_values(time_col).groupby(user_col)[item_col].agg(list).to_dict()\n","        self.user_ids = list(self.data.keys())\n","\n","        if num_negatives:\n","            self.all_items = df[item_col].unique()\n","\n","    def __len__(self):\n","\n","        return len(self.data)\n","\n","    def sample_negatives(self, item_sequence):\n","\n","        negatives = self.all_items[~np.isin(self.all_items, item_sequence)]\n","        if self.full_negative_sampling:\n","            negatives = np.random.choice(\n","                negatives, size=self.num_negatives * (len(item_sequence) - 1), replace=True)\n","            negatives = negatives.reshape(len(item_sequence) - 1, self.num_negatives)\n","        else:\n","            negatives = np.random.choice(negatives, size=self.num_negatives, replace=False)\n","\n","        return negatives\n","\n","\n","class CausalLMDataset(LMDataset):\n","\n","    def __init__(self, df, max_length=128, num_negatives=None, full_negative_sampling=True,\n","                 user_col='user_id', item_col='item_id', time_col='time_idx',\n","                 label_masking_probability=0):\n","\n","        super().__init__(df, max_length, num_negatives, full_negative_sampling,\n","                         user_col, item_col, time_col)\n","\n","        self.label_masking_probability = label_masking_probability\n","\n","    def __getitem__(self, idx):\n","\n","        item_sequence = self.data[self.user_ids[idx]]\n","\n","        if len(item_sequence) > self.max_length + 1:\n","            item_sequence = item_sequence[-self.max_length - 1:]\n","\n","        input_ids = np.array(item_sequence[:-1])\n","        labels = np.array(item_sequence[1:])\n","\n","        # for testing how masking labels influence performance\n","        if self.label_masking_probability > 0:\n","            mask = np.random.rand(len(labels)) < self.label_masking_probability\n","            labels[mask] = -100\n","\n","        if self.num_negatives:\n","            negatives = self.sample_negatives(item_sequence)\n","            return {'input_ids': input_ids, 'labels': labels, 'negatives': negatives}\n","\n","        return {'input_ids': input_ids, 'labels': labels}\n","\n","\n","class CausalLMPredictionDataset(LMDataset):\n","\n","    def __init__(self, df, max_length=128, validation_mode=False,\n","                 user_col='user_id', item_col='item_id',\n","                 time_col='time_idx'):\n","\n","        super().__init__(df, max_length=max_length, num_negatives=None,\n","                         user_col=user_col, item_col=item_col, time_col=time_col)\n","\n","        self.validation_mode = validation_mode\n","\n","    def __getitem__(self, idx):\n","\n","        user_id = self.user_ids[idx]\n","        item_sequence = self.data[user_id]\n","\n","        if self.validation_mode:\n","            target = item_sequence[-1]\n","            input_ids = item_sequence[-self.max_length-1:-1]\n","            item_sequence = item_sequence[:-1]\n","\n","            return {'input_ids': input_ids, 'user_id': user_id,\n","                    'full_history': item_sequence, 'target': target}\n","        else:\n","            input_ids = item_sequence[-self.max_length:]\n","\n","            return {'input_ids': input_ids, 'user_id': user_id,\n","                    'full_history': item_sequence}\n","\n","\n","class MaskedLMDataset(LMDataset):\n","\n","    def __init__(self, df, max_length=128,\n","                 num_negatives=None, full_negative_sampling=True,\n","                 mlm_probability=0.2,\n","                 masking_value=1, ignore_value=-100,\n","                 force_last_item_masking_prob=0,\n","                 user_col='user_id', item_col='item_id',\n","                 time_col='time_idx'):\n","\n","        super().__init__(df, max_length, num_negatives, full_negative_sampling,\n","                         user_col, item_col, time_col)\n","\n","        self.mlm_probability = mlm_probability\n","        self.masking_value = masking_value\n","        self.ignore_value = ignore_value\n","        self.force_last_item_masking_prob = force_last_item_masking_prob\n","\n","    def __getitem__(self, idx):\n","\n","        item_sequence = self.data[self.user_ids[idx]]\n","\n","        if len(item_sequence) > self.max_length:\n","            item_sequence = item_sequence[-self.max_length:]\n","\n","        input_ids = np.array(item_sequence)\n","        mask = np.random.rand(len(item_sequence)) < self.mlm_probability\n","        input_ids[mask] = self.masking_value\n","        if self.force_last_item_masking_prob > 0:\n","            if np.random.rand() < self.force_last_item_masking_prob:\n","                input_ids[-1] = self.masking_value\n","\n","        labels = np.array(item_sequence)\n","        labels[input_ids != self.masking_value] = self.ignore_value\n","\n","        if self.num_negatives:\n","            negatives = self.sample_negatives(item_sequence)\n","            return {'input_ids': input_ids, 'labels': labels, 'negatives': negatives}\n","\n","        return {'input_ids': input_ids, 'labels': labels}\n","\n","\n","class MaskedLMPredictionDataset(LMDataset):\n","\n","    def __init__(self, df, max_length=128, masking_value=1,\n","                 validation_mode=False,\n","                 user_col='user_id', item_col='item_id',\n","                 time_col='time_idx'):\n","\n","        super().__init__(df, max_length=max_length, num_negatives=None,\n","                         user_col=user_col, item_col=item_col, time_col=time_col)\n","\n","        self.masking_value = masking_value\n","        self.validation_mode = validation_mode\n","\n","    def __getitem__(self, idx):\n","\n","        user_id = self.user_ids[idx]\n","        item_sequence = self.data[user_id]\n","\n","        if self.validation_mode:\n","            target = item_sequence[-1]\n","            input_ids = item_sequence[-self.max_length:-1]\n","            item_sequence = item_sequence[:-1]\n","        else:\n","            input_ids = item_sequence[-self.max_length + 1:]\n","\n","        input_ids += [self.masking_value]\n","\n","        if self.validation_mode:\n","            return {'input_ids': input_ids, 'user_id': user_id,\n","                    'full_history': item_sequence, 'target': target}\n","        else:\n","            return {'input_ids': input_ids, 'user_id': user_id,\n","                    'full_history': item_sequence}\n","\n","\n","class PaddingCollateFn:\n","\n","    def __init__(self, padding_value=0, labels_padding_value=-100):\n","\n","        self.padding_value = padding_value\n","        self.labels_padding_value = labels_padding_value\n","\n","    def __call__(self, batch):\n","\n","        collated_batch = {}\n","\n","        for key in batch[0].keys():\n","\n","            if np.isscalar(batch[0][key]):\n","                collated_batch[key] = torch.tensor([example[key] for example in batch])\n","                continue\n","\n","            if key == 'labels':\n","                padding_value = self.labels_padding_value\n","            else:\n","                padding_value = self.padding_value\n","            values = [torch.tensor(example[key]) for example in batch]\n","            collated_batch[key] = pad_sequence(values, batch_first=True,\n","                                               padding_value=padding_value)\n","\n","        if 'input_ids' in collated_batch:\n","            attention_mask = collated_batch['input_ids'] != self.padding_value\n","            collated_batch['attention_mask'] = attention_mask.to(dtype=torch.float32)  \n","\n","        return collated_batch"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:50:00.319883Z","iopub.status.busy":"2024-10-25T16:50:00.318838Z","iopub.status.idle":"2024-10-25T16:50:01.099172Z","shell.execute_reply":"2024-10-25T16:50:01.098183Z","shell.execute_reply.started":"2024-10-25T16:50:00.319835Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Metrics.\n","\"\"\"\n","\n","import numpy as np\n","import torch\n","from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, recall_at_k\n","from tqdm.auto import tqdm\n","\n","\n","def compute_metrics(ground_truth, preds, k=10):\n","\n","    if not hasattr(ground_truth, 'rating'):\n","        ground_truth = ground_truth.assign(rating=1)\n","\n","    # when we have 1 true positive, HitRate == Recall and MRR == MAP\n","    metrics = {\n","        f'ndcg@{k}': ndcg_at_k(ground_truth, preds, col_user='user_id', col_item='item_id',\n","                               col_prediction='prediction', col_rating='rating', k=k),\n","        f'hit_rate@{k}': recall_at_k(ground_truth, preds, col_user='user_id', col_item='item_id',\n","                                     col_prediction='prediction', col_rating='rating', k=k),\n","        f'mrr@{k}': map_at_k(ground_truth, preds, col_user='user_id', col_item='item_id',\n","                             col_prediction='prediction', col_rating='rating', k=k),\n","        f'rec@{k}': recall_at_k(ground_truth, preds, col_user='user_id', col_item='item_id',\n","                             col_prediction='prediction', col_rating='rating', k=k)\n","    }\n","\n","    return metrics\n","\n","\n","def compute_sampled_metrics(seqrec_module, predict_dataset, test, item_counts,\n","                            popularity_sampling=True, num_negatives=100, k=10,\n","                            device='cuda'):\n","\n","    test = test.set_index('user_id')['item_id'].to_dict()\n","    all_items = item_counts.index.values\n","    item_weights = item_counts.values\n","    # probabilities = item_weights/item_weights.sum()\n","\n","    seqrec_module = seqrec_module.eval().to(device)\n","\n","    ndcg, hit_rate, mrr = 0.0, 0.0, 0.0\n","    user_count = 0\n","\n","    for user in tqdm(predict_dataset):\n","\n","        if user['user_id'] not in test:\n","            continue\n","\n","        positive = test[user['user_id']]\n","        indices = ~np.isin(all_items, user['full_history'])\n","        negatives = all_items[indices]\n","        if popularity_sampling:\n","            probabilities = item_weights[indices]\n","            probabilities = probabilities/probabilities.sum()\n","        else:\n","            probabilities = None\n","        negatives = np.random.choice(negatives, size=num_negatives,\n","                                     replace=False, p=probabilities)\n","        items = np.concatenate([np.array([positive]), negatives])\n","\n","        batch = {'input_ids': torch.tensor(user['input_ids']).unsqueeze(0).to(device),\n","                 'attention_mask': torch.tensor([1] * len(user['input_ids'])).unsqueeze(0).to(device)}\n","        pred = seqrec_module.prediction_output(batch)\n","        pred = pred[0, -1, items]\n","\n","        rank = (-pred).argsort().argsort()[0].item() + 1\n","        if rank <= k:\n","            ndcg += 1 / np.log2(rank + 1)\n","            hit_rate += 1\n","            mrr += 1 / rank\n","        user_count += 1\n","\n","    ndcg = ndcg / user_count\n","    hit_rate = hit_rate / user_count\n","    mrr = mrr / user_count\n","\n","    return {'ndcg': ndcg, 'hit_rate': hit_rate, 'mrr': mrr}"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:50:06.322945Z","iopub.status.busy":"2024-10-25T16:50:06.322332Z","iopub.status.idle":"2024-10-25T16:50:08.654712Z","shell.execute_reply":"2024-10-25T16:50:08.653637Z","shell.execute_reply.started":"2024-10-25T16:50:06.322903Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Models.\n","\"\"\"\n","\n","import numpy as np\n","import torch\n","from torch import nn\n","from transformers import BertConfig, BertModel, GPT2Config, GPT2Model\n","\n","\n","class BERT4Rec(nn.Module):\n","\n","    def __init__(self, vocab_size, bert_config, add_head=True,\n","                 tie_weights=True, padding_idx=0, init_std=0.02):\n","\n","        super().__init__()\n","\n","        self.vocab_size = vocab_size\n","        self.bert_config = bert_config\n","        self.add_head = add_head\n","        self.tie_weights = tie_weights\n","        self.padding_idx = padding_idx\n","        self.init_std = init_std\n","\n","        self.embed_layer = nn.Embedding(num_embeddings=vocab_size,\n","                                        embedding_dim=bert_config['hidden_size'],\n","                                        padding_idx=padding_idx)\n","        self.transformer_model = BertModel(BertConfig(**bert_config))\n","\n","        if self.add_head:\n","            self.head = nn.Linear(bert_config['hidden_size'], vocab_size, bias=False)\n","            if self.tie_weights:\n","                self.head.weight = self.embed_layer.weight\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","\n","        self.embed_layer.weight.data.normal_(mean=0.0, std=self.init_std)\n","        if self.padding_idx is not None:\n","            self.embed_layer.weight.data[self.padding_idx].zero_()\n","\n","    def forward(self, input_ids, attention_mask):\n","\n","        embeds = self.embed_layer(input_ids)\n","        transformer_outputs = self.transformer_model(\n","            inputs_embeds=embeds, attention_mask=attention_mask)\n","        outputs = transformer_outputs.last_hidden_state\n","\n","        if self.add_head:\n","            outputs = self.head(outputs)\n","\n","        return outputs\n","\n","\n","class SASRec(nn.Module):\n","    \"\"\"Adaptation of code from\n","    https://github.com/pmixer/SASRec.pytorch.\n","    \"\"\"\n","\n","    def __init__(self, item_num, maxlen=128, hidden_units=64, num_blocks=1,\n","                 num_heads=1, dropout_rate=0.1, initializer_range=0.02,\n","                 add_head=True):\n","\n","        super(SASRec, self).__init__()\n","\n","        self.item_num = item_num\n","        self.maxlen = maxlen\n","        self.hidden_units = hidden_units\n","        self.num_blocks = num_blocks\n","        self.num_heads = num_heads\n","        self.dropout_rate = dropout_rate\n","        self.initializer_range = initializer_range\n","        self.add_head = add_head\n","\n","        self.item_emb = nn.Embedding(item_num + 1, hidden_units, padding_idx=0)\n","        self.pos_emb = nn.Embedding(maxlen, hidden_units)\n","        self.emb_dropout = nn.Dropout(dropout_rate)\n","\n","        self.attention_layernorms = nn.ModuleList() # to be Q for self-attention\n","        self.attention_layers = nn.ModuleList()\n","        self.forward_layernorms = nn.ModuleList()\n","        self.forward_layers = nn.ModuleList()\n","\n","        self.last_layernorm = nn.LayerNorm(hidden_units, eps=1e-8)\n","\n","        for _ in range(num_blocks):\n","            new_attn_layernorm = nn.LayerNorm(hidden_units, eps=1e-8)\n","            self.attention_layernorms.append(new_attn_layernorm)\n","\n","            new_attn_layer = nn.MultiheadAttention(hidden_units,\n","                                                   num_heads,\n","                                                   dropout_rate)\n","            self.attention_layers.append(new_attn_layer)\n","\n","            new_fwd_layernorm = nn.LayerNorm(hidden_units, eps=1e-8)\n","            self.forward_layernorms.append(new_fwd_layernorm)\n","\n","            new_fwd_layer = PointWiseFeedForward(hidden_units, dropout_rate)\n","            self.forward_layers.append(new_fwd_layer)\n","\n","        # parameters initialization\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        \"\"\"Initialize weights.\n","\n","        Examples:\n","        https://github.com/huggingface/transformers/blob/v4.25.1/src/transformers/models/gpt2/modeling_gpt2.py#L454\n","        https://recbole.io/docs/_modules/recbole/model/sequential_recommender/sasrec.html#SASRec\n","        \"\"\"\n","\n","        if isinstance(module, (nn.Linear, nn.Conv1d)):\n","            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    # parameter attention mask added for compatibility with Lightning module, not used\n","    def forward(self, input_ids, attention_mask):\n","\n","        seqs = self.item_emb(input_ids)\n","        seqs *= self.item_emb.embedding_dim ** 0.5\n","        positions = np.tile(np.array(range(input_ids.shape[1])), [input_ids.shape[0], 1])\n","        # need to be on the same device\n","        seqs += self.pos_emb(torch.LongTensor(positions).to(seqs.device))\n","        seqs = self.emb_dropout(seqs)\n","\n","        timeline_mask = torch.Tensor(input_ids == 0)\n","        seqs *= ~timeline_mask.unsqueeze(-1) # broadcast in last dim\n","\n","        tl = seqs.shape[1] \n","        attention_mask = ~torch.tril(torch.ones((tl, tl), dtype=torch.bool).to(seqs.device))\n","\n","        for i in range(len(self.attention_layers)):\n","            seqs = torch.transpose(seqs, 0, 1)\n","            Q = self.attention_layernorms[i](seqs)\n","            mha_outputs, _ = self.attention_layers[i](Q, seqs, seqs, \n","                                            attn_mask=attention_mask)\n","                                            # key_padding_mask=timeline_mask\n","                                            # need_weights=False) this arg do not work?\n","            seqs = Q + mha_outputs\n","            seqs = torch.transpose(seqs, 0, 1)\n","\n","            seqs = self.forward_layernorms[i](seqs)\n","            seqs = self.forward_layers[i](seqs)\n","            seqs *=  ~timeline_mask.unsqueeze(-1)\n","\n","        outputs = self.last_layernorm(seqs) # (U, T, C) -> (U, -1, C)\n","        if self.add_head:\n","            outputs = torch.matmul(outputs, self.item_emb.weight.transpose(0, 1))\n","\n","        return outputs\n","\n","\n","class PointWiseFeedForward(nn.Module):\n","\n","    def __init__(self, hidden_units, dropout_rate):\n","\n","        super(PointWiseFeedForward, self).__init__()\n","\n","        self.conv1 = nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n","        self.dropout1 = nn.Dropout(p=dropout_rate)\n","        self.relu = nn.SiLU()\n","        self.conv2 = nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n","        self.dropout2 = nn.Dropout(p=dropout_rate)\n","\n","    def forward(self, inputs):\n","        outputs = self.dropout2(\n","            self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n","        outputs = outputs.transpose(-1, -2) # as Conv1D requires (N, C, Length)\n","        outputs += inputs\n","        return outputs"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:50:09.811674Z","iopub.status.busy":"2024-10-25T16:50:09.810765Z","iopub.status.idle":"2024-10-25T16:50:09.821115Z","shell.execute_reply":"2024-10-25T16:50:09.820360Z","shell.execute_reply.started":"2024-10-25T16:50:09.811632Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Filter interactions.\n","\"\"\"\n","\n","\n","def add_time_idx(df, user_col='user_id', timestamp_col='timestamp', sort=True):\n","    \"\"\"Add time index to interactions dataframe.\"\"\"\n","\n","    if sort:\n","        df = df.sort_values([user_col, timestamp_col])\n","\n","    df['time_idx'] = df.groupby(user_col).cumcount()\n","    df['time_idx_reversed'] = df.groupby(user_col).cumcount(ascending=False)\n","\n","    return df\n","\n","\n","def filter_items(df, item_min_count, item_col='item_id'):\n","\n","    print('Filtering items..')\n","\n","    item_count = df.groupby(item_col).user_id.nunique()\n","\n","    item_ids = item_count[item_count >= item_min_count].index\n","    print(f'Number of items before {len(item_count)}')\n","    print(f'Number of items after {len(item_ids)}')\n","\n","    print(f'Interactions length before: {len(df)}')\n","    df = df[df.item_id.isin(item_ids)]\n","    print(f'Interactions length after: {len(df)}')\n","\n","    return df\n","\n","\n","def filter_users(df, user_min_count, user_col='user_id'):\n","\n","    print('Filtering users..')\n","\n","    user_count = df.groupby(user_col).item_id.nunique()\n","\n","    user_ids = user_count[user_count >= user_min_count].index\n","    print(f'Number of users before {len(user_count)}')\n","    print(f'Number of users after {len(user_ids)}')\n","\n","    print(f'Interactions length before: {len(df)}')\n","    df = df[df.user_id.isin(user_ids)]\n","    print(f'Interactions length after: {len(df)}')\n","\n","    return df"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:50:11.596686Z","iopub.status.busy":"2024-10-25T16:50:11.596267Z","iopub.status.idle":"2024-10-25T16:50:11.603973Z","shell.execute_reply":"2024-10-25T16:50:11.603077Z","shell.execute_reply.started":"2024-10-25T16:50:11.596649Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Postprocessing.\n","\"\"\"\n","\n","import numpy as np\n","import pandas as pd\n","\n","\n","def preds2recs(preds, item_mapping=None):\n","\n","    user_ids = np.hstack([pred['user_ids'] for pred in preds])\n","    scores = np.vstack([pred['scores'] for pred in preds])\n","    preds = np.vstack([pred['preds'] for pred in preds])\n","\n","    user_ids = np.repeat(user_ids[:, None], repeats=scores.shape[1], axis=1)\n","\n","    recs = pd.DataFrame({'user_id': user_ids.flatten(),\n","                         'item_id': preds.flatten(),\n","                         'prediction': scores.flatten()})\n","\n","    if item_mapping is not None:\n","        recs.item_id = recs.item_id.map(item_mapping)\n","\n","    return recs"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:50:20.758095Z","iopub.status.busy":"2024-10-25T16:50:20.757623Z","iopub.status.idle":"2024-10-25T16:50:23.052761Z","shell.execute_reply":"2024-10-25T16:50:23.051821Z","shell.execute_reply.started":"2024-10-25T16:50:20.758050Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Pytorch Lightning Modules.\n","\"\"\"\n","\n","import numpy as np\n","import pytorch_lightning as pl\n","import torch\n","from torch import nn\n","\n","\n","class SeqRecBase(pl.LightningModule):\n","\n","    def __init__(self, model, lr=1e-3, padding_idx=0,\n","                 predict_top_k=10, filter_seen=True):\n","\n","        super().__init__()\n","\n","        self.model = model\n","        self.lr = lr\n","        self.padding_idx = padding_idx\n","        self.predict_top_k = predict_top_k\n","        self.filter_seen = filter_seen\n","\n","    def configure_optimizers(self):\n","\n","        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n","        return optimizer\n","\n","    def predict_step(self, batch, batch_idx):\n","\n","        preds, scores = self.make_prediction(batch)\n","\n","        scores = scores.detach().cpu().numpy()\n","        preds = preds.detach().cpu().numpy()\n","        user_ids = batch['user_id'].detach().cpu().numpy()\n","\n","        return {'preds': preds, 'scores': scores, 'user_ids': user_ids}\n","\n","    def validation_step(self, batch, batch_idx):\n","\n","        preds, scores = self.make_prediction(batch)\n","        metrics = self.compute_val_metrics(batch['target'], preds)\n","\n","        self.log(\"val_ndcg\", metrics['ndcg'], prog_bar=True)\n","        self.log(\"val_hit_rate\", metrics['hit_rate'], prog_bar=True)\n","        self.log(\"val_mrr\", metrics['mrr'], prog_bar=True)\n","\n","    def make_prediction(self, batch):\n","\n","        outputs = self.prediction_output(batch)\n","\n","        input_ids = batch['input_ids']\n","        rows_ids = torch.arange(input_ids.shape[0], dtype=torch.long, device=input_ids.device)\n","        last_item_idx = (input_ids != self.padding_idx).sum(axis=1) - 1\n","\n","        preds = outputs[rows_ids, last_item_idx, :]\n","\n","        scores, preds = torch.sort(preds, descending=True)\n","\n","        if self.filter_seen:\n","            seen_items = batch['full_history']\n","            preds, scores = self.filter_seen_items(preds, scores, seen_items)\n","        else:\n","            scores = scores[:, :self.predict_top_k]\n","            preds = preds[:, :self.predict_top_k]\n","\n","        return preds, scores\n","\n","    def filter_seen_items(self, preds, scores, seen_items):\n","\n","        max_len = seen_items.size(1)\n","        scores = scores[:, :self.predict_top_k + max_len]\n","        preds = preds[:, :self.predict_top_k + max_len]\n","\n","        final_preds, final_scores = [], []\n","        for i in range(preds.size(0)):\n","            not_seen_indexes = torch.isin(preds[i], seen_items[i], invert=True)\n","            pred = preds[i, not_seen_indexes][:self.predict_top_k]\n","            score = scores[i, not_seen_indexes][:self.predict_top_k]\n","            final_preds.append(pred)\n","            final_scores.append(score)\n","\n","        final_preds = torch.vstack(final_preds)\n","        final_scores = torch.vstack(final_scores)\n","\n","        return final_preds, final_scores\n","\n","    def compute_val_metrics(self, targets, preds):\n","\n","        ndcg, hit_rate, mrr, precision = 0, 0, 0, 0\n","\n","        for i, pred in enumerate(preds):\n","            if torch.isin(targets[i], pred).item():\n","                hit_rate += 1\n","                rank = torch.where(pred == targets[i])[0].item() + 1\n","                ndcg += 1 / np.log2(rank + 1)\n","                mrr += 1 / rank\n","\n","        hit_rate = hit_rate / len(targets)\n","        ndcg = ndcg / len(targets)\n","        mrr = mrr / len(targets)\n","\n","        return {'ndcg': ndcg, 'hit_rate': hit_rate, 'mrr': mrr}\n","\n","\n","class SeqRec(SeqRecBase):\n","\n","    def training_step(self, batch, batch_idx):\n","\n","        outputs = self.model(batch['input_ids'], batch['attention_mask'])\n","        loss = self.compute_loss(outputs, batch)\n","\n","        return loss\n","\n","    def compute_loss(self, outputs, batch):\n","\n","        loss_fct = nn.CrossEntropyLoss()\n","        loss = loss_fct(outputs.view(-1, outputs.size(-1)), batch['labels'].view(-1))\n","\n","        return loss\n","\n","    def prediction_output(self, batch):\n","\n","        return self.model(batch['input_ids'], batch['attention_mask'])\n","\n","\n","class SeqRecWithSampling(SeqRec):\n","\n","    def __init__(self, model, lr=1e-3, loss='cross_entropy',\n","                 padding_idx=0, predict_top_k=10, filter_seen=True):\n","\n","        super().__init__(model, lr, padding_idx, predict_top_k, filter_seen)\n","\n","        self.loss = loss\n","\n","        if hasattr(self.model, 'item_emb'):  # for SASRec\n","            self.embed_layer = self.model.item_emb\n","        elif hasattr(self.model, 'embed_layer'):\n","            self.embed_layer = self.model.embed_layer\n","\n","\n","    def compute_loss(self, outputs, batch):\n","\n","        # embed  and compute logits for negatives\n","        if batch['negatives'].ndim == 2:  # for full_negative_sampling=False\n","            # [N, M, D]\n","            embeds_negatives = self.embed_layer(batch['negatives'].to(torch.int32))\n","            # [N, T, D] * [N, D, M] -> [N, T, M]\n","            logits_negatives = torch.matmul(outputs, embeds_negatives.transpose(1, 2))\n","        elif batch['negatives'].ndim == 3:  # for full_negative_sampling=True\n","            # [N, T, M, D]\n","            embeds_negatives = self.embed_layer(batch['negatives'].to(torch.int32))\n","            # [N, T, 1, D] * [N, T, D, M] -> [N, T, 1, M] -> -> [N, T, M]\n","            logits_negatives = torch.matmul(\n","                outputs.unsqueeze(2), embeds_negatives.transpose(2, 3)).squeeze()\n","            if logits_negatives.ndim == 2:\n","                logits_negatives = logits_negatives.unsqueeze(2)\n","\n","        # embed  and compute logits for positives\n","        # [N, T]\n","        labels = batch['labels'].clone()\n","        labels[labels == -100] = self.padding_idx\n","        # [N, T, D]\n","        embeds_labels = self.embed_layer(labels)\n","        # [N, T, 1, D] * [N, T, D, 1] -> [N, T, 1, 1] -> [N, T]\n","        logits_labels = torch.matmul(outputs.unsqueeze(2), embeds_labels.unsqueeze(3)).squeeze()\n","\n","        # concat positives and negatives\n","        # [N, T, M + 1]\n","        logits = torch.cat([logits_labels.unsqueeze(2), logits_negatives], dim=-1)\n","\n","        # prepare targets for loss\n","        if self.loss == 'cross_entropy':\n","            # [N, T]\n","            targets = batch['labels'].clone()\n","            targets[targets != -100] = 0\n","        elif self.loss == 'bce':\n","            # [N, T, M + 1]\n","            targets = torch.zeros_like(logits)\n","            targets[:, :, 0] = 1\n","\n","        if self.loss == 'cross_entropy':\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, logits.size(-1)), targets.view(-1))\n","        elif self.loss == 'bce':\n","            # loss_fct = nn.BCEWithLogitsLoss()\n","            # loss = loss_fct(logits, targets)\n","            loss_fct = nn.BCEWithLogitsLoss(reduction='none')\n","            loss = loss_fct(logits, targets)\n","            loss = loss[batch['labels'] != -100]\n","            loss = loss.mean()\n","\n","        return loss\n","\n","    def prediction_output(self, batch):\n","\n","        outputs = self.model(batch['input_ids'], batch['attention_mask'])\n","        outputs = torch.matmul(outputs, self.embed_layer.weight.T)\n","\n","        return outputs"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:50:23.054706Z","iopub.status.busy":"2024-10-25T16:50:23.054169Z","iopub.status.idle":"2024-10-25T16:50:23.184792Z","shell.execute_reply":"2024-10-25T16:50:23.183996Z","shell.execute_reply.started":"2024-10-25T16:50:23.054669Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import pytorch_lightning as pl\n","import torch\n","from hydra import compose, initialize\n","from omegaconf import OmegaConf\n","from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, ModelSummary\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:23.667363Z","iopub.status.busy":"2024-10-25T16:51:23.666917Z","iopub.status.idle":"2024-10-25T16:51:24.049167Z","shell.execute_reply":"2024-10-25T16:51:24.048234Z","shell.execute_reply.started":"2024-10-25T16:51:23.667297Z"},"trusted":true},"outputs":[],"source":["# for SASRec\n","with initialize(version_base=None, config_path=\"./configs\"):\n","    config = compose(config_name=\"SASRec\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:26.667641Z","iopub.status.busy":"2024-10-25T16:51:26.667152Z","iopub.status.idle":"2024-10-25T16:51:26.674029Z","shell.execute_reply":"2024-10-25T16:51:26.672515Z","shell.execute_reply.started":"2024-10-25T16:51:26.667596Z"},"trusted":true},"outputs":[],"source":["OmegaConf.set_struct(config, False)\n","\n","config.dataset.max_length = 300\n","config.model_params.maxlen = 300\n","\n","config.dataset.num_negatives = 3000"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:27.266965Z","iopub.status.busy":"2024-10-25T16:51:27.266591Z","iopub.status.idle":"2024-10-25T16:51:27.275195Z","shell.execute_reply":"2024-10-25T16:51:27.274334Z","shell.execute_reply.started":"2024-10-25T16:51:27.266928Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda_visible_devices: 0\n","data_path: ../data/ml-1m.txt\n","dataset:\n","  max_length: 300\n","  full_negative_sampling: false\n","  num_negatives: 3000\n","dataloader:\n","  batch_size: 128\n","  test_batch_size: 256\n","  num_workers: 8\n","  validation_size: 10000\n","model: SASRec\n","model_params:\n","  maxlen: 300\n","  hidden_units: 64\n","  num_blocks: 2\n","  num_heads: 1\n","  dropout_rate: 0.1\n","seqrec_module:\n","  lr: 0.001\n","  predict_top_k: 10\n","  filter_seen: true\n","trainer_params:\n","  max_epochs: 100\n","patience: 10\n","sampled_metrics: false\n","top_k_metrics:\n","- 10\n","- 100\n","\n"]}],"source":["print(OmegaConf.to_yaml(config))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:27.838898Z","iopub.status.busy":"2024-10-25T16:51:27.838551Z","iopub.status.idle":"2024-10-25T16:51:28.334321Z","shell.execute_reply":"2024-10-25T16:51:28.333510Z","shell.execute_reply.started":"2024-10-25T16:51:27.838863Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('/kaggle/input/recsys-hse/events.csv')\n","item_counts = data['item_id'].value_counts()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:31.090182Z","iopub.status.busy":"2024-10-25T16:51:31.089349Z","iopub.status.idle":"2024-10-25T16:51:31.093861Z","shell.execute_reply":"2024-10-25T16:51:31.092991Z","shell.execute_reply.started":"2024-10-25T16:51:31.090138Z"},"trusted":true},"outputs":[],"source":["#data = filter_items(data, item_counts.quantile(0.25))"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:32.707388Z","iopub.status.busy":"2024-10-25T16:51:32.706410Z","iopub.status.idle":"2024-10-25T16:51:32.853336Z","shell.execute_reply":"2024-10-25T16:51:32.852432Z","shell.execute_reply.started":"2024-10-25T16:51:32.707341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(894149, 6)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","      <th>time_idx</th>\n","      <th>time_idx_reversed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1505</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>286</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>3669</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>285</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>584</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>284</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3390</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>283</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2885</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>282</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  item_id  rating  timestamp  time_idx  time_idx_reversed\n","0        0     1505       4          0         0                286\n","1        0     3669       3          1         1                285\n","2        0      584       4          2         2                284\n","3        0     3390       3          3         3                283\n","4        0     2885       4          4         4                282"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["data = add_time_idx(data, sort=False)\n","\n","# index 1 is used for masking value\n","if config.model == 'BERT4Rec':\n","    data.item_id += 1\n","\n","print(data.shape)\n","data.head()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:33.048082Z","iopub.status.busy":"2024-10-25T16:51:33.047177Z","iopub.status.idle":"2024-10-25T16:51:33.063473Z","shell.execute_reply":"2024-10-25T16:51:33.062596Z","shell.execute_reply.started":"2024-10-25T16:51:33.048018Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","      <th>time_idx</th>\n","      <th>time_idx_reversed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1505</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>286</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>3669</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>285</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>584</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>284</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3390</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>283</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2885</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>282</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>894144</th>\n","      <td>6039</td>\n","      <td>1453</td>\n","      <td>4</td>\n","      <td>223</td>\n","      <td>197</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>894145</th>\n","      <td>6039</td>\n","      <td>613</td>\n","      <td>5</td>\n","      <td>224</td>\n","      <td>198</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>894146</th>\n","      <td>6039</td>\n","      <td>1548</td>\n","      <td>4</td>\n","      <td>225</td>\n","      <td>199</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>894147</th>\n","      <td>6039</td>\n","      <td>241</td>\n","      <td>4</td>\n","      <td>226</td>\n","      <td>200</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>894148</th>\n","      <td>6039</td>\n","      <td>1177</td>\n","      <td>4</td>\n","      <td>227</td>\n","      <td>201</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>894149 rows × 6 columns</p>\n","</div>"],"text/plain":["        user_id  item_id  rating  timestamp  time_idx  time_idx_reversed\n","0             0     1505       4          0         0                286\n","1             0     3669       3          1         1                285\n","2             0      584       4          2         2                284\n","3             0     3390       3          3         3                283\n","4             0     2885       4          4         4                282\n","...         ...      ...     ...        ...       ...                ...\n","894144     6039     1453       4        223       197                  4\n","894145     6039      613       5        224       198                  3\n","894146     6039     1548       4        225       199                  2\n","894147     6039      241       4        226       200                  1\n","894148     6039     1177       4        227       201                  0\n","\n","[894149 rows x 6 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:34.434374Z","iopub.status.busy":"2024-10-25T16:51:34.433703Z","iopub.status.idle":"2024-10-25T16:51:34.463223Z","shell.execute_reply":"2024-10-25T16:51:34.462241Z","shell.execute_reply.started":"2024-10-25T16:51:34.434332Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>time_idx</th>\n","      <th>time_idx_reversed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1505</td>\n","      <td>0</td>\n","      <td>286</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>3669</td>\n","      <td>1</td>\n","      <td>285</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>584</td>\n","      <td>2</td>\n","      <td>284</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3390</td>\n","      <td>3</td>\n","      <td>283</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2885</td>\n","      <td>4</td>\n","      <td>282</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>894144</th>\n","      <td>6039</td>\n","      <td>1453</td>\n","      <td>197</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>894145</th>\n","      <td>6039</td>\n","      <td>613</td>\n","      <td>198</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>894146</th>\n","      <td>6039</td>\n","      <td>1548</td>\n","      <td>199</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>894147</th>\n","      <td>6039</td>\n","      <td>241</td>\n","      <td>200</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>894148</th>\n","      <td>6039</td>\n","      <td>1177</td>\n","      <td>201</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>894149 rows × 4 columns</p>\n","</div>"],"text/plain":["        user_id  item_id  time_idx  time_idx_reversed\n","0             0     1505         0                286\n","1             0     3669         1                285\n","2             0      584         2                284\n","3             0     3390         3                283\n","4             0     2885         4                282\n","...         ...      ...       ...                ...\n","894144     6039     1453       197                  4\n","894145     6039      613       198                  3\n","894146     6039     1548       199                  2\n","894147     6039      241       200                  1\n","894148     6039     1177       201                  0\n","\n","[894149 rows x 4 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data = data[['user_id','item_id','time_idx','time_idx_reversed']]\n","data"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:35.686168Z","iopub.status.busy":"2024-10-25T16:51:35.685798Z","iopub.status.idle":"2024-10-25T16:51:35.751063Z","shell.execute_reply":"2024-10-25T16:51:35.749976Z","shell.execute_reply.started":"2024-10-25T16:51:35.686133Z"},"trusted":true},"outputs":[],"source":["train = data[data.time_idx_reversed >= 2]\n","validation = data[data.time_idx_reversed == 1]\n","validation_full = data[data.time_idx_reversed >= 1]\n","test = data[data.time_idx_reversed == 0]\n","#test = data[(data.time_idx_reversed == 1) | (data.time_idx_reversed == 0)]"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:36.916646Z","iopub.status.busy":"2024-10-25T16:51:36.915947Z","iopub.status.idle":"2024-10-25T16:51:37.793844Z","shell.execute_reply":"2024-10-25T16:51:37.792807Z","shell.execute_reply.started":"2024-10-25T16:51:36.916601Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["validation_size = config.dataloader.validation_size\n","validation_users = validation_full.user_id.unique()\n","if validation_size and (validation_size < len(validation_users)):\n","    validation_users = np.random.choice(validation_users, size=validation_size, replace=False)\n","\n","if config.model == 'SASRec':\n","    train_dataset = CausalLMDataset(train, **config['dataset'])\n","    eval_dataset = CausalLMPredictionDataset(\n","        validation_full[validation_full.user_id.isin(validation_users)],\n","        max_length=config.dataset.max_length, validation_mode=True)\n","elif config.model == 'BERT4Rec':\n","    train_dataset = MaskedLMDataset(train, **config['dataset'])\n","    eval_dataset = MaskedLMPredictionDataset(\n","        validation_full[validation_full.user_id.isin(validation_users)],\n","        max_length=config.dataset.max_length, validation_mode=True)\n","\n","train_loader = DataLoader(\n","    train_dataset, shuffle=True,\n","    collate_fn=PaddingCollateFn(),\n","    batch_size=config.dataloader.batch_size,\n","    num_workers=config.dataloader.num_workers)\n","eval_loader = DataLoader(\n","    eval_dataset, shuffle=False,\n","    collate_fn=PaddingCollateFn(),\n","    batch_size=config.dataloader.test_batch_size,\n","    num_workers=config.dataloader.num_workers)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:38.371795Z","iopub.status.busy":"2024-10-25T16:51:38.371163Z","iopub.status.idle":"2024-10-25T16:51:38.966239Z","shell.execute_reply":"2024-10-25T16:51:38.965073Z","shell.execute_reply.started":"2024-10-25T16:51:38.371754Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([128, 300])\n"]}],"source":["batch = next(iter(train_loader))\n","print(batch['input_ids'].shape)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:42.341038Z","iopub.status.busy":"2024-10-25T16:51:42.340032Z","iopub.status.idle":"2024-10-25T16:51:42.369526Z","shell.execute_reply":"2024-10-25T16:51:42.368764Z","shell.execute_reply.started":"2024-10-25T16:51:42.340994Z"},"trusted":true},"outputs":[],"source":["item_count = data.item_id.max()\n","\n","if hasattr(config.dataset, 'num_negatives') and config.dataset.num_negatives:\n","    add_head = False\n","else:\n","    add_head = True\n","\n","if config.model == 'SASRec':\n","    model = SASRec(item_num=item_count, add_head=add_head, **config.model_params)\n","if config.model == 'BERT4Rec':\n","    model = BERT4Rec(vocab_size=item_count + 1, add_head=add_head,\n","                     bert_config=config.model_params)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:44.615338Z","iopub.status.busy":"2024-10-25T16:51:44.614554Z","iopub.status.idle":"2024-10-25T16:51:45.474762Z","shell.execute_reply":"2024-10-25T16:51:45.473738Z","shell.execute_reply.started":"2024-10-25T16:51:44.615274Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([128, 300, 64])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["out = model(batch['input_ids'], batch['attention_mask'])\n","out.shape"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T16:51:45.477286Z","iopub.status.busy":"2024-10-25T16:51:45.476651Z","iopub.status.idle":"2024-10-25T17:03:40.694697Z","shell.execute_reply":"2024-10-25T17:03:40.693679Z","shell.execute_reply.started":"2024-10-25T16:51:45.477237Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f971e9e6ba5d44eb92a3f86e64f34b13","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if hasattr(config.dataset, 'num_negatives') and config.dataset.num_negatives:\n","    seqrec_module = SeqRecWithSampling(model, **config['seqrec_module'])\n","else:\n","    seqrec_module = SeqRec(model, **config['seqrec_module'])\n","    \n","early_stopping = EarlyStopping(monitor=\"val_hit_rate\", mode=\"max\",\n","                               patience=config.patience, verbose=False)\n","model_summary = ModelSummary(max_depth=2)\n","checkpoint = ModelCheckpoint(save_top_k=1, monitor=\"val_hit_rate\",\n","                             mode=\"max\", save_weights_only=True)\n","callbacks=[early_stopping, model_summary, checkpoint]\n","\n","trainer = pl.Trainer(callbacks=callbacks, enable_checkpointing=True, log_every_n_steps=48,\n","                      **config['trainer_params'])\n","\n","trainer.fit(model=seqrec_module,\n","            train_dataloaders=train_loader,\n","            val_dataloaders=eval_loader)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T17:03:40.698212Z","iopub.status.busy":"2024-10-25T17:03:40.697236Z","iopub.status.idle":"2024-10-25T17:03:40.715362Z","shell.execute_reply":"2024-10-25T17:03:40.714384Z","shell.execute_reply.started":"2024-10-25T17:03:40.698158Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_128/937832759.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  seqrec_module.load_state_dict(torch.load(checkpoint.best_model_path)['state_dict'])\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["seqrec_module.load_state_dict(torch.load(checkpoint.best_model_path)['state_dict'])"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T17:03:40.717093Z","iopub.status.busy":"2024-10-25T17:03:40.716737Z","iopub.status.idle":"2024-10-25T17:03:45.592538Z","shell.execute_reply":"2024-10-25T17:03:45.591363Z","shell.execute_reply.started":"2024-10-25T17:03:40.717059Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3251b7366f4943e8adae15e3edf6f24d","version_major":2,"version_minor":0},"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(604000, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2397</td>\n","      <td>5.370092</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1052</td>\n","      <td>5.327501</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1149</td>\n","      <td>4.887436</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3660</td>\n","      <td>4.646952</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>3657</td>\n","      <td>4.585503</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  item_id  prediction\n","0        0     2397    5.370092\n","1        0     1052    5.327501\n","2        0     1149    4.887436\n","3        0     3660    4.646952\n","4        0     3657    4.585503"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["if config.model == 'SASRec':\n","    predict_dataset = CausalLMPredictionDataset(train, max_length=config.dataset.max_length)\n","elif config.model  == 'BERT4Rec':\n","    predict_dataset = MaskedLMPredictionDataset(train, max_length=config.dataset.max_length)\n","\n","predict_loader = DataLoader(\n","        predict_dataset, shuffle=False,\n","        collate_fn=PaddingCollateFn(),\n","        batch_size=config.dataloader.test_batch_size,\n","        num_workers=config.dataloader.num_workers)\n","\n","seqrec_module.predict_top_k = max(config.top_k_metrics)\n","preds = trainer.predict(model=seqrec_module, dataloaders=predict_loader)\n","\n","recs = preds2recs(preds)\n","print(recs.shape)\n","recs.head()"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T17:03:45.595627Z","iopub.status.busy":"2024-10-25T17:03:45.595273Z","iopub.status.idle":"2024-10-25T17:03:57.481249Z","shell.execute_reply":"2024-10-25T17:03:57.480133Z","shell.execute_reply.started":"2024-10-25T17:03:45.595591Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/recommenders/evaluation/python_evaluation.py:438: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n","  df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n","/opt/conda/lib/python3.10/site-packages/recommenders/evaluation/python_evaluation.py:439: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n","  rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n"]},{"name":"stdout","output_type":"stream","text":["k =  10\n","{'ndcg@10': 0.1645274776603075, 'hit_rate@10': 0.30596026490066225, 'mrr@10': 0.12155517449805528, 'rec@10': 0.30596026490066225}\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/recommenders/evaluation/python_evaluation.py:438: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n","  df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n","/opt/conda/lib/python3.10/site-packages/recommenders/evaluation/python_evaluation.py:439: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n","  rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n"]},{"name":"stdout","output_type":"stream","text":["k =  100\n","{'ndcg@100': 0.24897708019162168, 'hit_rate@100': 0.7168874172185431, 'mrr@100': 0.1374267546473959, 'rec@100': 0.7168874172185431}\n"]}],"source":["for k in config.top_k_metrics:\n","    metrics_val = compute_metrics(validation, recs, k=k)\n","    print('k = ', k)\n","    print(metrics_val)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T17:03:57.482821Z","iopub.status.busy":"2024-10-25T17:03:57.482479Z","iopub.status.idle":"2024-10-25T17:04:02.426725Z","shell.execute_reply":"2024-10-25T17:04:02.425571Z","shell.execute_reply.started":"2024-10-25T17:03:57.482785Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3e30efcf08b43f2ba9ed8393a792520","version_major":2,"version_minor":0},"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"name":"stdout","output_type":"stream","text":["(604000, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1461</td>\n","      <td>4.502969</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>3421</td>\n","      <td>4.169186</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1332</td>\n","      <td>4.122826</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2397</td>\n","      <td>3.698641</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2480</td>\n","      <td>3.600317</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  item_id  prediction\n","0        0     1461    4.502969\n","1        0     3421    4.169186\n","2        0     1332    4.122826\n","3        0     2397    3.698641\n","4        0     2480    3.600317"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["if config.model == 'SASRec':\n","    test_predict_dataset = CausalLMPredictionDataset(validation_full, max_length=config.dataset.max_length)\n","elif config.model  == 'BERT4Rec':\n","    test_predict_dataset = MaskedLMPredictionDataset(validation_full, max_length=config.dataset.max_length)\n","    \n","test_predict_loader = DataLoader(\n","        test_predict_dataset, shuffle=False,\n","        collate_fn=PaddingCollateFn(),\n","        batch_size=config.dataloader.test_batch_size,\n","        num_workers=config.dataloader.num_workers)\n","\n","seqrec_module.predict_top_k = max(config.top_k_metrics)\n","preds_test = trainer.predict(model=seqrec_module, dataloaders=test_predict_loader)\n","\n","recs_test = preds2recs(preds_test)\n","print(recs_test.shape)\n","recs_test.head()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T17:04:02.428631Z","iopub.status.busy":"2024-10-25T17:04:02.428249Z","iopub.status.idle":"2024-10-25T17:04:14.338585Z","shell.execute_reply":"2024-10-25T17:04:14.337629Z","shell.execute_reply.started":"2024-10-25T17:04:02.428593Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/recommenders/evaluation/python_evaluation.py:438: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n","  df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n","/opt/conda/lib/python3.10/site-packages/recommenders/evaluation/python_evaluation.py:439: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n","  rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n"]},{"name":"stdout","output_type":"stream","text":["k =  10\n","{'ndcg@10': 0.16467296460923264, 'hit_rate@10': 0.2993377483443709, 'mrr@10': 0.12366853253442656, 'rec@10': 0.2993377483443709}\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/recommenders/evaluation/python_evaluation.py:438: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n","  df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n","/opt/conda/lib/python3.10/site-packages/recommenders/evaluation/python_evaluation.py:439: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n","  rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n"]},{"name":"stdout","output_type":"stream","text":["k =  100\n","{'ndcg@100': 0.24654160480381876, 'hit_rate@100': 0.6991721854304636, 'mrr@100': 0.1389707304112343, 'rec@100': 0.6991721854304636}\n"]}],"source":["for k in config.top_k_metrics:\n","    metrics_test = compute_metrics(test, recs_test, k=k)\n","    print('k = ', k)\n","    print(metrics_test)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T17:04:14.340386Z","iopub.status.busy":"2024-10-25T17:04:14.339952Z","iopub.status.idle":"2024-10-25T17:04:14.565018Z","shell.execute_reply":"2024-10-25T17:04:14.564057Z","shell.execute_reply.started":"2024-10-25T17:04:14.340338Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[1461, 3421, 1332, 2397, 2480, 2606, 3271, 150...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[232, 1246, 1686, 3656, 452, 1822, 3101, 933, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[2354, 2774, 1687, 1560, 1781, 452, 382, 724, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>[1560, 989, 605, 1316, 2564, 3272, 461, 67, 10...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>[802, 2185, 3035, 2814, 1868, 1337, 270, 702, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6035</th>\n","      <td>6035</td>\n","      <td>[2054, 1811, 2256, 2646, 2366, 2606, 3529, 305...</td>\n","    </tr>\n","    <tr>\n","      <th>6036</th>\n","      <td>6036</td>\n","      <td>[3692, 3142, 2054, 2732, 401, 3013, 772, 3529,...</td>\n","    </tr>\n","    <tr>\n","      <th>6037</th>\n","      <td>6037</td>\n","      <td>[2256, 3059, 2732, 1102, 1379, 2833, 2502, 196...</td>\n","    </tr>\n","    <tr>\n","      <th>6038</th>\n","      <td>6038</td>\n","      <td>[450, 1893, 3309, 2420, 2305, 3605, 405, 79, 8...</td>\n","    </tr>\n","    <tr>\n","      <th>6039</th>\n","      <td>6039</td>\n","      <td>[870, 2067, 3551, 3151, 401, 190, 1593, 573, 2...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6040 rows × 2 columns</p>\n","</div>"],"text/plain":["      user_id                                            item_id\n","0           0  [1461, 3421, 1332, 2397, 2480, 2606, 3271, 150...\n","1           1  [232, 1246, 1686, 3656, 452, 1822, 3101, 933, ...\n","2           2  [2354, 2774, 1687, 1560, 1781, 452, 382, 724, ...\n","3           3  [1560, 989, 605, 1316, 2564, 3272, 461, 67, 10...\n","4           4  [802, 2185, 3035, 2814, 1868, 1337, 270, 702, ...\n","...       ...                                                ...\n","6035     6035  [2054, 1811, 2256, 2646, 2366, 2606, 3529, 305...\n","6036     6036  [3692, 3142, 2054, 2732, 401, 3013, 772, 3529,...\n","6037     6037  [2256, 3059, 2732, 1102, 1379, 2833, 2502, 196...\n","6038     6038  [450, 1893, 3309, 2420, 2305, 3605, 405, 79, 8...\n","6039     6039  [870, 2067, 3551, 3151, 401, 190, 1593, 573, 2...\n","\n","[6040 rows x 2 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["top_10_recs = recs_test.groupby('user_id').head(10)\n","subs = top_10_recs.groupby('user_id')['item_id'].apply(list).reset_index()\n","subs"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T17:04:14.566533Z","iopub.status.busy":"2024-10-25T17:04:14.566175Z","iopub.status.idle":"2024-10-25T17:04:14.593951Z","shell.execute_reply":"2024-10-25T17:04:14.592990Z","shell.execute_reply.started":"2024-10-25T17:04:14.566497Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1461 3421 1332 2397 2480 2606 3271 1501 331 213</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>232 1246 1686 3656 452 1822 3101 933 350 1884</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2354 2774 1687 1560 1781 452 382 724 221 3035</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1560 989 605 1316 2564 3272 461 67 106 810</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>802 2185 3035 2814 1868 1337 270 702 3404 1687</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6035</th>\n","      <td>6035</td>\n","      <td>2054 1811 2256 2646 2366 2606 3529 3059 3382 463</td>\n","    </tr>\n","    <tr>\n","      <th>6036</th>\n","      <td>6036</td>\n","      <td>3692 3142 2054 2732 401 3013 772 3529 2664 1039</td>\n","    </tr>\n","    <tr>\n","      <th>6037</th>\n","      <td>6037</td>\n","      <td>2256 3059 2732 1102 1379 2833 2502 1968 2664 2646</td>\n","    </tr>\n","    <tr>\n","      <th>6038</th>\n","      <td>6038</td>\n","      <td>450 1893 3309 2420 2305 3605 405 79 84 1337</td>\n","    </tr>\n","    <tr>\n","      <th>6039</th>\n","      <td>6039</td>\n","      <td>870 2067 3551 3151 401 190 1593 573 215 2277</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6040 rows × 2 columns</p>\n","</div>"],"text/plain":["      user_id                                            item_id\n","0           0    1461 3421 1332 2397 2480 2606 3271 1501 331 213\n","1           1      232 1246 1686 3656 452 1822 3101 933 350 1884\n","2           2      2354 2774 1687 1560 1781 452 382 724 221 3035\n","3           3         1560 989 605 1316 2564 3272 461 67 106 810\n","4           4     802 2185 3035 2814 1868 1337 270 702 3404 1687\n","...       ...                                                ...\n","6035     6035   2054 1811 2256 2646 2366 2606 3529 3059 3382 463\n","6036     6036    3692 3142 2054 2732 401 3013 772 3529 2664 1039\n","6037     6037  2256 3059 2732 1102 1379 2833 2502 1968 2664 2646\n","6038     6038        450 1893 3309 2420 2305 3605 405 79 84 1337\n","6039     6039       870 2067 3551 3151 401 190 1593 573 215 2277\n","\n","[6040 rows x 2 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["def array_to_str(arr):\n","    return ' '.join(map(str, arr))\n","\n","subs['item_id'] = subs['item_id'].apply(array_to_str)\n","subs"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T17:04:14.595683Z","iopub.status.busy":"2024-10-25T17:04:14.595301Z","iopub.status.idle":"2024-10-25T17:04:14.627711Z","shell.execute_reply":"2024-10-25T17:04:14.626830Z","shell.execute_reply.started":"2024-10-25T17:04:14.595636Z"},"trusted":true},"outputs":[],"source":["subs.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5874350,"sourceId":9623935,"sourceType":"datasetVersion"},{"datasetId":5875233,"sourceId":9721427,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
